import { NextRequest, NextResponse } from 'next/server'
import OpenAI from 'openai'
import { ChunkerService, ChunkingTier } from '@/lib/services/chunker'
import { Chunk } from '@/lib/services/chunker/types'

const openai = new OpenAI({
  apiKey: process.env.OPENAI_API_KEY || '',
})

const chunkerService = new ChunkerService()

const LANG_MAP: Record<string, string> = {
  vi: 'Vietnamese',
  en: 'English',
  zh: 'Chinese (Simplified)',
  ja: 'Japanese',
  ko: 'Korean',
  fr: 'French',
  es: 'Spanish',
  de: 'German',
}

// Translate a single chunk
async function translateChunk(
  chunk: Chunk,
  targetLanguage: string,
  model: string,
  chunkIndex: number,
  totalChunks: number
): Promise<string> {
  const completion = await openai.chat.completions.create({
    model,
    messages: [
      {
        role: 'system',
        content: totalChunks > 1 
          ? `Translate to ${targetLanguage}. This is part ${chunkIndex + 1} of ${totalChunks} of a longer text. Maintain consistency with previous parts. Return only the translation.`
          : `Translate to ${targetLanguage}. Return only the translation, nothing else.`
      },
      { role: 'user', content: chunk.content }
    ],
    temperature: 0.3,
    max_tokens: Math.min(chunk.tokens * 3, 4000), // Estimate output tokens
  })
  
  return completion.choices[0]?.message?.content?.trim() || ''
}

export async function POST(req: NextRequest) {
  try {
    // Check API key
    if (!process.env.OPENAI_API_KEY) {
      return NextResponse.json(
        { success: false, error: 'Missing OpenAI API key' },
        { status: 500 }
      )
    }

    const body = await req.json()
    const { text = '', targetLang = 'vi', isRewrite = false, tier = 'standard' } = body

    if (!text.trim()) {
      return NextResponse.json(
        { success: false, error: 'Text is empty' },
        { status: 400 }
      )
    }

    const targetLanguage = LANG_MAP[targetLang] || 'Vietnamese'
    const model = tier === 'premium' ? 'gpt-4' : 'gpt-3.5-turbo'
    
    console.log('=== Translation Request ===')
    console.log('Target:', targetLanguage)
    console.log('Text length:', text.length)
    console.log('Model:', model)
    console.log('Tier:', tier)

    // Handle rewrite differently
    if (isRewrite) {
      const messages = [
        {
          role: 'system' as const,
          content: `Rewrite this ${targetLanguage} text to be clearer. Return only the rewritten text.`
        },
        { role: 'user' as const, content: text }
      ]

      const completion = await openai.chat.completions.create({
        model,
        messages,
        temperature: 0.3,
        max_tokens: Math.min(text.length + 500, 3500),
      })

      const translated = completion.choices[0]?.message?.content?.trim() || ''

      return NextResponse.json({
        success: true,
        original: text,
        translated,
        targetLang,
        model,
        isRewrite: true,
        method: 'rewrite'
      })
    }

    // Use ChunkerService for translation
    console.log('=== Using ChunkerService ===')
    
    // Analyze document
    const analysis = await chunkerService.analyzeDocument(text)
    console.log('Document analysis:', {
      estimatedTokens: analysis.estimatedTokens,
      recommendedTier: analysis.recommendedTier
    })
    
    // Map translation tier to chunking tier
    const chunkingTier: ChunkingTier = tier as ChunkingTier
    
    // Chunk the document
    const chunkingResult = await chunkerService.chunkDocument(text, chunkingTier, {
      generateDNA: tier === 'premium'
    })
    
    console.log(`Created ${chunkingResult.chunks.length} chunks`)
    console.log('Chunk sizes:', chunkingResult.chunks.map(c => ({
      tokens: c.tokens,
      chars: c.content.length
    })))
    
    // Translate each chunk
    const translatedChunks: string[] = []
    const chunks = chunkingResult.chunks
    
    // Determine batch size based on tier
    const batchSize = tier === 'basic' ? 3 : tier === 'standard' ? 2 : 1
    
    for (let i = 0; i < chunks.length; i += batchSize) {
      const batch = chunks.slice(i, Math.min(i + batchSize, chunks.length))
      
      console.log(`Translating batch ${Math.floor(i / batchSize) + 1}/${Math.ceil(chunks.length / batchSize)}...`)
      
      // Translate batch in parallel
      const batchTranslations = await Promise.all(
        batch.map((chunk, batchIndex) => 
          translateChunk(
            chunk,
            targetLanguage,
            model,
            i + batchIndex,
            chunks.length
          )
        )
      )
      
      translatedChunks.push(...batchTranslations)
      
      // Add delay between batches to avoid rate limits
      if (i + batchSize < chunks.length) {
        await new Promise(resolve => setTimeout(resolve, tier === 'basic' ? 100 : 200))
      }
    }
    
    // Join translated chunks
    const translated = translatedChunks.join('\n\n')
    
    console.log('Translation complete')
    console.log('Original length:', text.length)
    console.log('Translated length:', translated.length)
    console.log('Total chunks:', chunks.length)
    console.log('Total tokens:', chunkingResult.totalTokens)
    
    // Include chunk metadata if premium tier
    const metadata: any = {
      chunks: chunks.length,
      totalTokens: chunkingResult.totalTokens,
      model,
      tier,
      method: 'chunked'
    }
    
    if (tier === 'premium' && chunks[0]?.metadata?.dna) {
      metadata.documentDNA = {
        languages: [...new Set(chunks.map(c => c.metadata?.dna?.language).filter(Boolean))],
        styles: [...new Set(chunks.map(c => c.metadata?.dna?.style).filter(Boolean))],
        hasCode: chunks.some(c => c.metadata?.dna?.hasCode),
        hasTable: chunks.some(c => c.metadata?.dna?.hasTable)
      }
    }

    return NextResponse.json({
      success: true,
      original: text,
      translated,
      targetLang,
      ...metadata
    })

  } catch (error: any) {
    console.error('=== Translation Error ===')
    console.error('Type:', error.constructor.name)
    console.error('Message:', error.message)
    console.error('Stack:', error.stack)

    // Specific error messages
    if (error.status === 401) {
      return NextResponse.json(
        { success: false, error: 'Invalid OpenAI API key' },
        { status: 401 }
      )
    }

    if (error.status === 429) {
      return NextResponse.json(
        { success: false, error: 'Rate limit exceeded. Please try again later.' },
        { status: 429 }
      )
    }

    if (error.message?.includes('timeout')) {
      return NextResponse.json(
        { success: false, error: 'Translation timeout. Text is too long.' },
        { status: 504 }
      )
    }

    return NextResponse.json(
      { 
        success: false, 
        error: error.message || 'Translation failed'
      },
      { status: 500 }
    )
  }
}