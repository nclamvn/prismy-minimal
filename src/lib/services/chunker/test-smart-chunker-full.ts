import { SmartChunkingStrategy } from './strategies/smart.strategy'
import { ChunkerService } from './index'

async function testFullChunking() {
  console.log('üß™ FULL SMART CHUNKER TEST\n')
  
  // Test 1: Multi-language document
  const multiLangDoc = `
# Introduction to AI Translation

Artificial Intelligence has revolutionized the way we handle multilingual communication.

## English Section

This section demonstrates how the chunker handles English text with various complexities.

### Technical Details

The implementation uses advanced NLP techniques:
- Tokenization with GPT-3 encoder
- Context-aware chunking
- DNA extraction for metadata

\`\`\`javascript
function translate(text, targetLang) {
  const tokens = tokenize(text);
  return processTokens(tokens, targetLang);
}
\`\`\`

## Vietnamese Section - Ph·∫ßn Ti·∫øng Vi·ªát

C√¥ng ngh·ªá AI ƒë√£ thay ƒë·ªïi c√°ch ch√∫ng ta x·ª≠ l√Ω d·ªãch thu·∫≠t. H·ªá th·ªëng chunking th√¥ng minh c√≥ th·ªÉ:
- Nh·∫≠n di·ªán ng√¥n ng·ªØ t·ª± ƒë·ªông
- T√°ch vƒÉn b·∫£n theo ng·ªØ c·∫£nh
- B·∫£o to√†n c·∫•u tr√∫c t√†i li·ªáu

### V√≠ d·ª• Th·ª±c T·∫ø

Khi d·ªãch t√†i li·ªáu k·ªπ thu·∫≠t, vi·ªác gi·ªØ nguy√™n format v√† context l√† r·∫•t quan tr·ªçng.

## Mixed Language Example

Sometimes we need to handle Ê∑∑ÂêàËØ≠Ë®Ä (mixed languages) trong c√πng m·ªôt document. 
This is particularly challenging for tokenization.

## Conclusion

The smart chunking system handles multiple languages efficiently while preserving document structure.
`.trim()

  // Test v·ªõi SmartChunkingStrategy tr·ª±c ti·∫øp
  console.log('=== Test 1: SmartChunkingStrategy Direct ===')
  const smartChunker = new SmartChunkingStrategy()
  
  const chunks = await smartChunker.chunk(multiLangDoc, {
    maxTokens: 100,
    overlap: 20,
    preserveStructure: true,
    generateDNA: true
  })
  
  console.log(`Total chunks: ${chunks.length}`)
  console.log(`Document tokens: ${smartChunker.countTokens(multiLangDoc)}`)
  
  // Analyze chunks
  for (let i = 0; i < chunks.length; i++) {
    const chunk = chunks[i]
    console.log(`\n--- Chunk ${i + 1} ---`)
    console.log(`ID: ${chunk.id.substring(0, 16)}...`)
    console.log(`Tokens: ${chunk.tokens}`)
    console.log(`Content: "${chunk.content.substring(0, 60)}..."`)
    
    if (chunk.metadata?.dna) {
      const dna = chunk.metadata.dna
      console.log(`Language: ${dna.language}`)
      console.log(`Style: ${dna.style}`)
      console.log(`Complexity: ${dna.complexity}/10`)
      console.log(`Topics: ${dna.topics.slice(0, 3).join(', ')}`)
      console.log(`Has Code: ${dna.hasCode}`)
    }
    
    console.log(`Links: prev=${chunk.metadata?.prevChunkId?.substring(0, 8) || 'none'}, next=${chunk.metadata?.nextChunkId?.substring(0, 8) || 'none'}`)
  }
  
  // Test 2: Using ChunkerService
  console.log('\n\n=== Test 2: ChunkerService with Tiers ===')
  const chunkerService = new ChunkerService()
  
  // Analyze document first
  const analysis = await chunkerService.analyzeDocument(multiLangDoc)
  console.log('Document Analysis:')
  console.log(`- Estimated tokens: ${analysis.estimatedTokens}`)
  console.log(`- Estimated chunks:`)
  console.log(`  - Basic: ${analysis.estimatedChunks.basic}`)
  console.log(`  - Standard: ${analysis.estimatedChunks.standard}`)
  console.log(`  - Premium: ${analysis.estimatedChunks.premium}`)
  console.log(`- Recommended tier: ${analysis.recommendedTier}`)
  
  // Test each tier
  for (const tier of ['basic', 'standard', 'premium'] as const) {
    console.log(`\n--- Testing ${tier.toUpperCase()} tier ---`)
    const tierInfo = chunkerService.getTierInfo(tier)
    console.log(`Description: ${tierInfo.description}`)
    
    const result = await chunkerService.chunkDocument(multiLangDoc, tier)
    console.log(`Chunks: ${result.chunks.length}`)
    console.log(`Total tokens: ${result.totalTokens}`)
    console.log(`Processing time: ${result.metadata.processingTime}ms`)
    
    // Show first chunk
    if (result.chunks.length > 0) {
      const firstChunk = result.chunks[0]
      console.log(`First chunk preview: "${firstChunk.content.substring(0, 50)}..."`)
    }
  }
  
  // Test 3: Edge cases
  console.log('\n\n=== Test 3: Edge Cases ===')
  
  // Empty text
  try {
    await chunkerService.chunkDocument('', 'standard')
  } catch (error) {
    console.log('‚úÖ Empty text handled:', error.message)
  }
  
  // Very short text
  const shortText = 'Hello world!'
  const shortResult = await chunkerService.chunkDocument(shortText, 'standard')
  console.log(`‚úÖ Short text (${shortText.length} chars) ‚Üí ${shortResult.chunks.length} chunk`)
  
  // Unicode heavy text
  const unicodeText = 'üöÄ Emoji test ‰Ω†Â•Ω‰∏ñÁïå „Åì„Çì„Å´„Å°„ÅØ üéâ'
  const unicodeResult = await chunkerService.chunkDocument(unicodeText, 'standard')
  console.log(`‚úÖ Unicode text ‚Üí ${unicodeResult.chunks.length} chunk, ${unicodeResult.totalTokens} tokens`)
}

// Run tests
testFullChunking().catch(console.error)